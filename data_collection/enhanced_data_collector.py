"""
ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘ê¸°
- íˆ¬ììë³„ ë§¤ë§¤ (ê¸°ê´€, ì™¸êµ­ì¸, ê°œì¸, í”„ë¡œê·¸ë¨)
- ê³µì‹œ ì •ë³´ (DART)
- ë‰´ìŠ¤ ê°ì„± ë¶„ì„
- ì‹œì¥/ì—…ì¢… ìƒí™©

ì‹¤ì œ ìƒê´€ê´€ê³„ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
"""

import pandas as pd
import numpy as np
from pykrx import stock
from datetime import datetime, timedelta
import time
import json
from pathlib import Path
import requests
from bs4 import BeautifulSoup
import warnings
warnings.filterwarnings('ignore')


class EnhancedDataCollector:
    """ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘ ë° ìƒê´€ê´€ê³„ ë¶„ì„"""
    
    def __init__(self):
        self.base_dir = Path('./data/crash_rebound')
        self.output_dir = Path('./data/enhanced')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        print("ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì¤‘...")
        self.df_base = pd.read_parquet(self.base_dir / 'all_stocks_3years.parquet')
        print(f"âœ… {len(self.df_base):,}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ\n")
        
        # ê¸‰ë½ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œ
        self.df_crashes = self.df_base[self.df_base['crash'] == 1].copy()
        
        # dateê°€ ì¸ë±ìŠ¤ì¸ ê²½ìš° ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        if 'date' not in self.df_crashes.columns and self.df_crashes.index.name == 'date':
            self.df_crashes = self.df_crashes.reset_index()
        
        print(f"ğŸ“Š ê¸‰ë½ ì´ë²¤íŠ¸: {len(self.df_crashes):,}ê°œ")
        print(f"   - ì„±ê³µ ë°˜ë“±: {self.df_crashes['success'].sum():,}ê°œ ({self.df_crashes['success'].sum()/len(self.df_crashes)*100:.1f}%)")
        print(f"   - ì‹¤íŒ¨: {(~self.df_crashes['success']).sum():,}ê°œ\n")
    
    # =========================================
    # 1. íˆ¬ììë³„ ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘
    # =========================================
    
    def collect_investor_data(self):
        """
        íˆ¬ììë³„ ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ ë° ìƒê´€ê´€ê³„ ë¶„ì„
        
        í•µì‹¬ ì§ˆë¬¸:
        1. ì™¸êµ­ì¸ ëŒ€ëŸ‰ ë§¤ë„ ì¢…ëª©ì€ ì •ë§ ë°˜ë“± ì•ˆí•˜ë‚˜?
        2. í”„ë¡œê·¸ë¨ ë§¤ë„ ì¢…ëª©ì€?
        3. ê¸°ê´€ ë§¤ìˆ˜ ì „í™˜ ì‹œ ë°˜ë“±ë¥ ì€?
        """
        print("="*70)
        print("1ï¸âƒ£ íˆ¬ììë³„ ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘")
        print("="*70 + "\n")
        
        # ë‚ ì§œë³„ë¡œ ì¢…ëª© ê·¸ë£¹í™”
        date_stocks = self.df_crashes.groupby('date')['stock_code'].apply(list).to_dict()
        
        all_investor_data = []
        total_dates = len(date_stocks)
        
        for idx, (date, stock_codes) in enumerate(date_stocks.items(), 1):
            if idx % 50 == 0:
                print(f"ì§„í–‰: {idx}/{total_dates} ({idx/total_dates*100:.1f}%)")
            
            try:
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                date_str = pd.to_datetime(date).strftime('%Y%m%d')
                
                # í•´ë‹¹ ë‚ ì§œì˜ ëª¨ë“  ì¢…ëª© íˆ¬ìì ë§¤ë§¤ ì¡°íšŒ
                for stock_code in stock_codes:
                    try:
                        # ê¸‰ë½ ë‹¹ì¼ íˆ¬ìì ë§¤ë§¤
                        df_investor = stock.get_market_trading_value_by_date(
                            date_str, date_str, stock_code
                        )
                        
                        if not df_investor.empty:
                            all_investor_data.append({
                                'date': date,
                                'stock_code': stock_code,
                                'institution_net': df_investor['ê¸°ê´€ê³„'].iloc[0] if 'ê¸°ê´€ê³„' in df_investor.columns else 0,
                                'foreign_net': df_investor['ì™¸êµ­ì¸'].iloc[0] if 'ì™¸êµ­ì¸' in df_investor.columns else 0,
                                'individual_net': df_investor['ê°œì¸'].iloc[0] if 'ê°œì¸' in df_investor.columns else 0,
                            })
                            
                            # í”„ë¡œê·¸ë¨ ë§¤ë§¤ (ë³„ë„ API)
                            try:
                                df_program = stock.get_market_trading_value_by_date(
                                    date_str, date_str, stock_code, detail=True
                                )
                                if not df_program.empty and 'í”„ë¡œê·¸ë¨' in df_program.columns:
                                    all_investor_data[-1]['program_net'] = df_program['í”„ë¡œê·¸ë¨'].iloc[0]
                                else:
                                    all_investor_data[-1]['program_net'] = 0
                            except:
                                all_investor_data[-1]['program_net'] = 0
                        
                        time.sleep(0.05)  # API ì œí•œ íšŒí”¼
                        
                    except Exception as e:
                        continue
                        
            except Exception as e:
                continue
        
        # DataFrame ë³€í™˜
        df_investor = pd.DataFrame(all_investor_data)
        
        print(f"\nâœ… íˆ¬ìì ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df_investor):,}ê±´")
        
        # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
        df_merged = self.df_crashes.merge(
            df_investor,
            on=['date', 'stock_code'],
            how='left'
        )
        
        # ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ ì±„ìš°ê¸°
        for col in ['institution_net', 'foreign_net', 'individual_net', 'program_net']:
            df_merged[col] = df_merged[col].fillna(0)
        
        # ì €ì¥
        output_file = self.output_dir / 'crashes_with_investor.parquet'
        df_merged.to_parquet(output_file)
        print(f"ğŸ’¾ ì €ì¥: {output_file}\n")
        
        # ìƒê´€ê´€ê³„ ë¶„ì„
        self._analyze_investor_correlation(df_merged)
        
        return df_merged
    
    def _analyze_investor_correlation(self, df):
        """íˆ¬ìì ë§¤ë§¤ì™€ ë°˜ë“±ë¥  ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("="*70)
        print("ğŸ“Š íˆ¬ìì ë§¤ë§¤ vs ë°˜ë“±ë¥  ìƒê´€ê´€ê³„ ë¶„ì„")
        print("="*70 + "\n")
        
        # 1. ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ 
        print("1ï¸âƒ£ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ ")
        print("-" * 70)
        
        df['foreign_group'] = pd.cut(
            df['foreign_net'] / 100000000,  # ì–µì› ë‹¨ìœ„
            bins=[-np.inf, -100, -50, -10, 0, 10, 50, 100, np.inf],
            labels=['-100ì–µ ì´í•˜', '-100~-50ì–µ', '-50~-10ì–µ', '-10~0ì–µ', 
                   '0~10ì–µ', '10~50ì–µ', '50~100ì–µ', '100ì–µ ì´ìƒ']
        )
        
        foreign_analysis = df.groupby('foreign_group').agg({
            'success': ['count', 'sum', 'mean'],
            'rebound_d5': 'mean'
        }).round(3)
        
        print(foreign_analysis)
        print()
        
        # 2. í”„ë¡œê·¸ë¨ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ 
        print("2ï¸âƒ£ í”„ë¡œê·¸ë¨ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ ")
        print("-" * 70)
        
        df['program_group'] = pd.cut(
            df['program_net'] / 100000000,
            bins=[-np.inf, -100, -50, -10, 0, 10, 50, 100, np.inf],
            labels=['-100ì–µ ì´í•˜', '-100~-50ì–µ', '-50~-10ì–µ', '-10~0ì–µ', 
                   '0~10ì–µ', '10~50ì–µ', '50~100ì–µ', '100ì–µ ì´ìƒ']
        )
        
        program_analysis = df.groupby('program_group').agg({
            'success': ['count', 'sum', 'mean'],
            'rebound_d5': 'mean'
        }).round(3)
        
        print(program_analysis)
        print()
        
        # 3. ê¸°ê´€ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ 
        print("3ï¸âƒ£ ê¸°ê´€ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„ ë°˜ë“±ë¥ ")
        print("-" * 70)
        
        df['institution_group'] = pd.cut(
            df['institution_net'] / 100000000,
            bins=[-np.inf, -50, -10, 0, 10, 50, np.inf],
            labels=['-50ì–µ ì´í•˜', '-50~-10ì–µ', '-10~0ì–µ', '0~10ì–µ', '10~50ì–µ', '50ì–µ ì´ìƒ']
        )
        
        institution_analysis = df.groupby('institution_group').agg({
            'success': ['count', 'sum', 'mean'],
            'rebound_d5': 'mean'
        }).round(3)
        
        print(institution_analysis)
        print()
        
        # 4. ë³µí•© ì¡°ê±´ ë¶„ì„
        print("4ï¸âƒ£ ë³µí•© ì¡°ê±´ë³„ ë°˜ë“±ë¥ ")
        print("-" * 70)
        
        conditions = {
            'ì™¸êµ­ì¸+ê¸°ê´€ ëª¨ë‘ ë§¤ë„ (-10ì–µ ì´ìƒ)': 
                (df['foreign_net'] < -1000000000) & (df['institution_net'] < -1000000000),
            'ì™¸êµ­ì¸+í”„ë¡œê·¸ë¨ ëª¨ë‘ ë§¤ë„ (-10ì–µ ì´ìƒ)': 
                (df['foreign_net'] < -1000000000) & (df['program_net'] < -1000000000),
            'ì™¸êµ­ì¸ ëŒ€ëŸ‰ ë§¤ë„ (-50ì–µ ì´ìƒ)': 
                df['foreign_net'] < -5000000000,
            'í”„ë¡œê·¸ë¨ ëŒ€ëŸ‰ ë§¤ë„ (-50ì–µ ì´ìƒ)': 
                df['program_net'] < -5000000000,
            'ì™¸êµ­ì¸+ê¸°ê´€ ëª¨ë‘ ë§¤ìˆ˜': 
                (df['foreign_net'] > 0) & (df['institution_net'] > 0),
            'ì™¸êµ­ì¸ ëŒ€ëŸ‰ ë§¤ìˆ˜ (+50ì–µ ì´ìƒ)': 
                df['foreign_net'] > 5000000000,
        }
        
        for condition_name, condition in conditions.items():
            filtered = df[condition]
            if len(filtered) > 0:
                success_rate = filtered['success'].mean() * 100
                avg_rebound = filtered['rebound_d5'].mean() * 100
                count = len(filtered)
                print(f"{condition_name}:")
                print(f"  ê±´ìˆ˜: {count:,}ê°œ, ì„±ê³µë¥ : {success_rate:.1f}%, í‰ê·  ë°˜ë“±: {avg_rebound:+.2f}%")
            else:
                print(f"{condition_name}: ë°ì´í„° ì—†ìŒ")
        
        print()
        
        # ê²°ê³¼ ì €ì¥
        analysis_result = {
            'foreign_analysis': foreign_analysis.to_dict(),
            'program_analysis': program_analysis.to_dict(),
            'institution_analysis': institution_analysis.to_dict()
        }
        
        with open(self.output_dir / 'investor_correlation_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2, default=str)
    
    # =========================================
    # 2. ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
    # =========================================
    
    def collect_disclosure_data(self, dart_api_key=None):
        """
        ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ë° ìƒê´€ê´€ê³„ ë¶„ì„
        
        í•µì‹¬ ì§ˆë¬¸:
        1. ìœ ìƒì¦ì ê³µì‹œ í›„ ê¸‰ë½ â†’ ì •ë§ ë°˜ë“± ì•ˆí•˜ë‚˜?
        2. ì‹¤ì  ì•…í™” ê³µì‹œ í›„ ê¸‰ë½ â†’ ë°˜ë“±ë¥ ì€?
        3. ì–´ë–¤ ê³µì‹œê°€ ì§„ì§œ ì•…ì¬ì¸ê°€?
        """
        print("="*70)
        print("2ï¸âƒ£ ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„")
        print("="*70 + "\n")
        
        if not dart_api_key:
            print("âš ï¸ DART API í‚¤ê°€ ì—†ì–´ ìƒ˜í”Œ ë¶„ì„ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            print("ì‹¤ì œ ìˆ˜ì§‘ì„ ìœ„í•´ì„œëŠ” https://opendart.fss.or.kr ì—ì„œ API í‚¤ ë°œê¸‰ í•„ìš”\n")
            
            # ê°„ë‹¨í•œ ê³µì‹œ í‚¤ì›Œë“œ í¬ë¡¤ë§ìœ¼ë¡œ ëŒ€ì²´
            return self._collect_disclosure_simple()
        
        # DART API ì‚¬ìš© (ì‹¤ì œ êµ¬í˜„)
        # TODO: API í‚¤ ë°œê¸‰ í›„ êµ¬í˜„
        pass
    
    def _collect_disclosure_simple(self):
        """
        ê°„ë‹¨í•œ ê³µì‹œ ì •ë³´ ìˆ˜ì§‘ (ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§)
        
        ê¸‰ë½ ì „í›„ 7ì¼ê°„ ì£¼ìš” ê³µì‹œ í‚¤ì›Œë“œ í™•ì¸
        """
        print("ğŸ“° ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ê³µì‹œ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n")
        
        # ìƒ˜í”Œ: ìœ ìƒì¦ì, ê°ì‚¬ì˜ê²¬, ì‹¤ì  ê´€ë ¨ í‚¤ì›Œë“œ
        disclosure_keywords = {
            'ìœ ìƒì¦ì': -0.5,  # ì•½í•œ ì•…ì¬
            'ë¬´ìƒì¦ì': 0.3,   # í˜¸ì¬
            'ìì‚¬ì£¼ë§¤ì…': 0.7, # í˜¸ì¬
            'ê°ì‚¬ì˜ê²¬': -0.9,  # ê°•í•œ ì•…ì¬
            'íš¡ë ¹': -1.0,      # ìµœì•…
            'ë°°ì„': -1.0,
            'ì˜ì—…ì´ìµ': 0.0,   # ë‚´ìš© í™•ì¸ í•„ìš”
            'ìˆ˜ì£¼': 0.5,       # í˜¸ì¬
            'ê³„ì•½': 0.4,
            'ë°°ë‹¹': 0.3,
        }
        
        all_disclosures = []
        
        # ê¸‰ë½ ì´ë²¤íŠ¸ë³„ë¡œ ì²˜ë¦¬
        for idx, row in self.df_crashes.head(100).iterrows():  # ìƒ˜í”Œ 100ê°œ
            stock_code = row['stock_code']
            date = pd.to_datetime(row['date'])
            
            # ê¸‰ë½ ì „í›„ 7ì¼
            start_date = date - timedelta(days=7)
            end_date = date + timedelta(days=1)
            
            try:
                # ë„¤ì´ë²„ ê¸ˆìœµ ê³µì‹œ í˜ì´ì§€
                url = f"https://finance.naver.com/item/news_notice.naver?code={stock_code}&page=1"
                
                response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ê³µì‹œ ì œëª© ì¶”ì¶œ
                notices = soup.select('.title')
                
                found_disclosures = []
                for notice in notices[:10]:  # ìµœê·¼ 10ê°œë§Œ
                    title = notice.get_text().strip()
                    
                    # í‚¤ì›Œë“œ ë§¤ì¹­
                    for keyword, impact in disclosure_keywords.items():
                        if keyword in title:
                            found_disclosures.append({
                                'keyword': keyword,
                                'impact': impact,
                                'title': title
                            })
                
                if found_disclosures:
                    all_disclosures.append({
                        'stock_code': stock_code,
                        'date': date,
                        'disclosures': found_disclosures,
                        'success': row['success'],
                        'rebound_d5': row['rebound_d5']
                    })
                
                time.sleep(0.5)  # í¬ë¡¤ë§ ì œí•œ
                
            except Exception as e:
                continue
        
        # ë¶„ì„
        if all_disclosures:
            self._analyze_disclosure_correlation(all_disclosures)
        
        return all_disclosures
    
    def _analyze_disclosure_correlation(self, disclosures):
        """ê³µì‹œì™€ ë°˜ë“±ë¥  ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\n" + "="*70)
        print("ğŸ“Š ê³µì‹œ í‚¤ì›Œë“œë³„ ë°˜ë“±ë¥  ë¶„ì„")
        print("="*70 + "\n")
        
        # í‚¤ì›Œë“œë³„ ê·¸ë£¹í™”
        keyword_stats = {}
        
        for item in disclosures:
            for disc in item['disclosures']:
                keyword = disc['keyword']
                
                if keyword not in keyword_stats:
                    keyword_stats[keyword] = {
                        'count': 0,
                        'success_count': 0,
                        'total_rebound': 0
                    }
                
                keyword_stats[keyword]['count'] += 1
                if item['success']:
                    keyword_stats[keyword]['success_count'] += 1
                keyword_stats[keyword]['total_rebound'] += item['rebound_d5']
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"{'ê³µì‹œ í‚¤ì›Œë“œ':<15} {'ê±´ìˆ˜':>6} {'ì„±ê³µë¥ ':>8} {'í‰ê·  ë°˜ë“±ë¥ ':>12}")
        print("-" * 70)
        
        for keyword, stats in sorted(keyword_stats.items(), key=lambda x: x[1]['count'], reverse=True):
            count = stats['count']
            success_rate = stats['success_count'] / count * 100
            avg_rebound = stats['total_rebound'] / count * 100
            
            print(f"{keyword:<15} {count:>6} {success_rate:>7.1f}% {avg_rebound:>11.2f}%")
        
        print()
    
    # =========================================
    # 3. ì‹¤í–‰
    # =========================================
    
    def run(self, mode='all'):
        """
        ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì‹¤í–‰
        
        Args:
            mode: 'investor', 'disclosure', 'news', 'all'
        """
        print(f"\n{'='*70}")
        print(f"ğŸš€ ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ëª¨ë“œ: {mode})")
        print(f"{'='*70}\n")
        
        results = {}
        
        if mode in ['investor', 'all']:
            print("\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2~3ì‹œê°„")
            print("ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Enterë¡œ ê³„ì†, Ctrl+Cë¡œ ì¤‘ë‹¨)\n")
            
            results['investor'] = self.collect_investor_data()
        
        if mode in ['disclosure', 'all']:
            results['disclosure'] = self.collect_disclosure_data()
        
        print(f"\n{'='*70}")
        print("âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ!")
        print(f"{'='*70}\n")
        
        return results


def main():
    """ì‹¤í–‰"""
    import sys
    
    collector = EnhancedDataCollector()
    
    # ëª…ë ¹í–‰ ì¸ìë¡œ ëª¨ë“œ ì„ íƒ
    mode = sys.argv[1] if len(sys.argv) > 1 else 'investor'
    
    collector.run(mode=mode)


if __name__ == '__main__':
    main()
