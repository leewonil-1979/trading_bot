"""
íˆ¬ìì ë§¤ë§¤ vs ë°˜ë“±ë¥  ìƒê´€ê´€ê³„ ë¹ ë¥¸ ê²€ì¦
- ê°œë³„ íŒŒì¼ì—ì„œ ê¸‰ë½ ì´ë²¤íŠ¸ 100ê°œ ìƒ˜í”Œ ì¶”ì¶œ
- pykrxë¡œ íˆ¬ìì ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘
- ì‹¤ì œ ìƒê´€ê´€ê³„ ë¶„ì„
- 30ë¶„ ì™„ë£Œ!
"""

import pandas as pd
import numpy as np
from pykrx import stock
from datetime import datetime, timedelta
from pathlib import Path
import time
import json

print("="*70)
print("âš¡ íˆ¬ìì ë§¤ë§¤ vs ë°˜ë“±ë¥  ë¹ ë¥¸ ê²€ì¦ (30ë¶„ ì™„ë£Œ)")
print("="*70 + "\n")

# 1. ê°œë³„ íŒŒì¼ì—ì„œ ê¸‰ë½ ì´ë²¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ
print("1ï¸âƒ£ ê¸‰ë½ ì´ë²¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ")
print("-" * 70)

crash_rebound_dir = Path('./data/crash_rebound')
individual_files = [f for f in crash_rebound_dir.glob('*.parquet') 
                   if f.name != 'all_stocks_3years.parquet']

print(f"ê°œë³„ íŒŒì¼: {len(individual_files)}ê°œ")

all_crashes = []
target_samples = 200  # 200ê°œ ìƒ˜í”Œ

for file in individual_files[:50]:  # ì²˜ìŒ 50ê°œ íŒŒì¼ë§Œ
    try:
        df = pd.read_parquet(file)
        df_crash = df[df['crash'] == 1].copy()
        
        if len(df_crash) > 0:
            # date ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
            df_crash = df_crash.reset_index()
            df_crash['date'] = pd.to_datetime(df_crash['Date'])
            
            for _, row in df_crash.iterrows():
                all_crashes.append({
                    'stock_code': row['stock_code'],
                    'stock_name': row['stock_name'],
                    'date': row['date'],
                    'crash_rate': row['crash_rate'],
                    'rebound_d5': row['rebound_d5'],
                    'success': row['success'],
                    'volume': row['volume']
                })
                
                if len(all_crashes) >= target_samples:
                    break
        
        if len(all_crashes) >= target_samples:
            break
            
    except Exception as e:
        continue

df_crashes = pd.DataFrame(all_crashes)
print(f"âœ… ê¸‰ë½ ìƒ˜í”Œ: {len(df_crashes)}ê°œ ì¶”ì¶œ ì™„ë£Œ\n")

# 2. íˆ¬ìì ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘
print("2ï¸âƒ£ íˆ¬ìì ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘")
print("-" * 70)

investor_data = []

for idx, row in df_crashes.iterrows():
    if int(idx) % 20 == 0:  # type: ignore
        print(f"ì§„í–‰: {idx}/{len(df_crashes)} ({int(idx)/len(df_crashes)*100:.1f}%)")  # type: ignore
    
    try:
        date_str = row['date'].strftime('%Y%m%d')
        
        # íˆ¬ìì ë§¤ë§¤ ì¡°íšŒ
        df_investor = stock.get_market_trading_value_by_date(
            date_str, date_str, row['stock_code']
        )
        
        if not df_investor.empty:
            investor_data.append({
                'stock_code': row['stock_code'],
                'date': row['date'],
                'institution_net': int(df_investor['ê¸°ê´€í•©ê³„'].iloc[0]) if 'ê¸°ê´€í•©ê³„' in df_investor.columns else 0,  # type: ignore
                'foreign_net': int(df_investor['ì™¸êµ­ì¸í•©ê³„'].iloc[0]) if 'ì™¸êµ­ì¸í•©ê³„' in df_investor.columns else 0,  # type: ignore
                'individual_net': df_investor['ê°œì¸'].iloc[0] if 'ê°œì¸' in df_investor.columns else 0,
            })
        
        time.sleep(0.1)  # API ì œí•œ
        
    except Exception as e:
        continue

df_investor = pd.DataFrame(investor_data)
print(f"\nâœ… íˆ¬ìì ë§¤ë§¤: {len(df_investor)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ\n")

# 3. ë°ì´í„° ë³‘í•©
print("3ï¸âƒ£ ë°ì´í„° ë³‘í•©")
print("-" * 70)

df_merged = df_crashes.merge(
    df_investor,
    on=['stock_code', 'date'],
    how='left'
)

# ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ
for col in ['institution_net', 'foreign_net', 'individual_net']:
    df_merged[col] = df_merged[col].fillna(0)

print(f"ë³‘í•© ì™„ë£Œ: {len(df_merged)}í–‰\n")

# 4. ìƒê´€ê´€ê³„ ë¶„ì„
print("="*70)
print("ğŸ“Š íˆ¬ìì ë§¤ë§¤ vs ë°˜ë“±ë¥  ìƒê´€ê´€ê³„ ë¶„ì„")
print("="*70 + "\n")

# 4-1. ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„
print("1ï¸âƒ£ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ vs ë°˜ë“±ë¥ ")
print("-" * 70)

df_merged['foreign_group'] = pd.cut(
    df_merged['foreign_net'] / 100000000,
    bins=[-np.inf, -50, -10, 0, 10, 50, np.inf],
    labels=['ëŒ€ëŸ‰ ë§¤ë„ (-50ì–µ+)', 'ë§¤ë„ (-10~50ì–µ)', 'ì†Œí­ ë§¤ë„', 'ë§¤ìˆ˜', 'ì ê·¹ ë§¤ìˆ˜ (+10~50ì–µ)', 'ëŒ€ëŸ‰ ë§¤ìˆ˜ (+50ì–µ+)']
)

result = df_merged.groupby('foreign_group').agg({
    'success': ['count', 'sum', 'mean'],
    'rebound_d5': 'mean'
})

result.columns = ['ê±´ìˆ˜', 'ì„±ê³µ', 'ì„±ê³µë¥ ', 'í‰ê·  ë°˜ë“±ë¥ ']
result['ì„±ê³µë¥ '] = (result['ì„±ê³µë¥ '] * 100).round(1)
result['í‰ê·  ë°˜ë“±ë¥ '] = (result['í‰ê·  ë°˜ë“±ë¥ '] * 100).round(2)

print(result)
print()

# 4-2. ê¸°ê´€ ìˆœë§¤ìˆ˜ êµ¬ê°„ë³„
print("2ï¸âƒ£ ê¸°ê´€ ìˆœë§¤ìˆ˜ vs ë°˜ë“±ë¥ ")
print("-" * 70)

df_merged['institution_group'] = pd.cut(
    df_merged['institution_net'] / 100000000,
    bins=[-np.inf, -30, -10, 0, 10, 30, np.inf],
    labels=['ëŒ€ëŸ‰ ë§¤ë„', 'ë§¤ë„', 'ì†Œí­ ë§¤ë„', 'ë§¤ìˆ˜', 'ì ê·¹ ë§¤ìˆ˜', 'ëŒ€ëŸ‰ ë§¤ìˆ˜']
)

result2 = df_merged.groupby('institution_group').agg({
    'success': ['count', 'sum', 'mean'],
    'rebound_d5': 'mean'
})

result2.columns = ['ê±´ìˆ˜', 'ì„±ê³µ', 'ì„±ê³µë¥ ', 'í‰ê·  ë°˜ë“±ë¥ ']
result2['ì„±ê³µë¥ '] = (result2['ì„±ê³µë¥ '] * 100).round(1)
result2['í‰ê·  ë°˜ë“±ë¥ '] = (result2['í‰ê·  ë°˜ë“±ë¥ '] * 100).round(2)

print(result2)
print()

# 4-3. í•µì‹¬ ê²°ë¡ 
print("="*70)
print("ğŸ¯ í•µì‹¬ ê²°ë¡ ")
print("="*70 + "\n")

# ì™¸êµ­ì¸ ëŒ€ëŸ‰ ë§¤ë„ vs ë‚˜ë¨¸ì§€
foreign_sell = df_merged[df_merged['foreign_net'] < -5000000000]
foreign_other = df_merged[df_merged['foreign_net'] >= -5000000000]

print(f"ì™¸êµ­ì¸ ëŒ€ëŸ‰ ë§¤ë„ (-50ì–µ ì´ìƒ):")
if len(foreign_sell) > 0:
    print(f"  ê±´ìˆ˜: {len(foreign_sell)}ê°œ")
    print(f"  ì„±ê³µë¥ : {foreign_sell['success'].mean()*100:.1f}%")
    print(f"  í‰ê·  ë°˜ë“±: {foreign_sell['rebound_d5'].mean()*100:.2f}%")
else:
    print(f"  ë°ì´í„° ì—†ìŒ")

print(f"\në‚˜ë¨¸ì§€:")
print(f"  ê±´ìˆ˜: {len(foreign_other)}ê°œ")
print(f"  ì„±ê³µë¥ : {foreign_other['success'].mean()*100:.1f}%")
print(f"  í‰ê·  ë°˜ë“±: {foreign_other['rebound_d5'].mean()*100:.2f}%")

# ê²°ê³¼ ì €ì¥
print(f"\n\nğŸ’¾ ê²°ê³¼ ì €ì¥")
print("-" * 70)

output_file = './data/enhanced/quick_verification_result.parquet'
df_merged.to_parquet(output_file)
print(f"âœ… {output_file}")

analysis_result = {
    'foreign_analysis': result.to_dict(),
    'institution_analysis': result2.to_dict(),
    'sample_count': len(df_merged),
    'data_collected': len(df_investor)
}

json_file = './data/enhanced/quick_verification_analysis.json'
with open(json_file, 'w', encoding='utf-8') as f:
    json.dump(analysis_result, f, ensure_ascii=False, indent=2, default=str)
print(f"âœ… {json_file}")

print(f"\n" + "="*70)
print("âœ… ê²€ì¦ ì™„ë£Œ!")
print("="*70)
