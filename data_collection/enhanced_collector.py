"""
ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ê¸°
- í”„ë¡œê·¸ë¨ ë§¤ë§¤ (ë„¤ì´ë²„ ì¦ê¶Œ)
- ê³µì‹œ ë°ì´í„° (DART API)
- ë‰´ìŠ¤ ë°ì´í„° (ë„¤ì´ë²„ ë‰´ìŠ¤)
"""

import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import json
from pathlib import Path
import re


class EnhancedDataCollector:
    """ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, data_dir='./data/crash_rebound'):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # DART API í‚¤ (https://opendart.fss.or.kr/ì—ì„œ ë°œê¸‰ í•„ìš”)
        self.dart_api_key = None
        
        # ì§„í–‰ìƒí™© ì €ì¥
        self.progress_file = self.data_dir / 'enhanced_progress.json'
        self.load_progress()
    
    def load_progress(self):
        """ì§„í–‰ìƒí™© ë¡œë“œ"""
        if self.progress_file.exists():
            with open(self.progress_file, 'r') as f:
                self.progress = json.load(f)
        else:
            self.progress = {'completed': []}
    
    def save_progress(self, stock_code):
        """ì§„í–‰ìƒí™© ì €ì¥"""
        if stock_code not in self.progress['completed']:
            self.progress['completed'].append(stock_code)
        with open(self.progress_file, 'w') as f:
            json.dump(self.progress, f)
    
    # =========================================
    # 1. í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë°ì´í„° (ë„¤ì´ë²„ ì¦ê¶Œ)
    # =========================================
    
    def collect_program_trading(self, stock_code, start_date, end_date):
        """í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ (ë„¤ì´ë²„ ì¦ê¶Œ)"""
        try:
            url = f"https://finance.naver.com/item/frgn.naver?code={stock_code}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            tables = soup.find_all('table', class_='type2')
            
            if len(tables) < 2:
                return None
            
            # í”„ë¡œê·¸ë¨ ë§¤ë§¤ í…Œì´ë¸”
            table = tables[1]
            rows = table.find_all('tr')[2:]
            
            data = []
            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 7:
                    continue
                
                try:
                    date_str = cols[0].text.strip()
                    if not date_str:
                        continue
                    
                    date = pd.to_datetime(date_str, format='%Y.%m.%d')
                    program_text = cols[6].text.strip().replace(',', '').replace('+', '')
                    program_net = int(program_text) if program_text else 0
                    
                    data.append({'Date': date, 'program_net': program_net})
                except:
                    continue
            
            if not data:
                return None
            
            df = pd.DataFrame(data).set_index('Date')
            df = df[(df.index >= pd.to_datetime(start_date)) & 
                   (df.index <= pd.to_datetime(end_date))]
            
            return df
            
        except Exception as e:
            print(f"   âš ï¸ í”„ë¡œê·¸ë¨ ë§¤ë§¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    # =========================================
    # 2. ê³µì‹œ ë°ì´í„° (DART API)
    # =========================================
    
    def collect_disclosure(self, stock_code, start_date, end_date):
        """ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ (í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°)"""
        # DART API í‚¤ ì—†ìœ¼ë©´ ë”ë¯¸ ë°˜í™˜
        date_range = pd.date_range(start_date, end_date, freq='D')
        df = pd.DataFrame({
            'Date': date_range,
            'disclosure_count': 0,
            'disclosure_impact': 0
        })
        return df.set_index('Date')
    
    # =========================================
    # 3. ë‰´ìŠ¤ ë°ì´í„° (ë„¤ì´ë²„ ë‰´ìŠ¤)
    # =========================================
    
    def collect_news_sentiment(self, stock_name, date):
        """íŠ¹ì • ë‚ ì§œì˜ ë‰´ìŠ¤ ê°ì„± ë¶„ì„"""
        try:
            search_date = date.strftime('%Y.%m.%d')
            query = f"{stock_name}"
            
            url = "https://search.naver.com/search.naver"
            params = {
                'where': 'news',
                'query': query,
                'sort': 0,
                'ds': search_date,
                'de': search_date
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            news_items = soup.find_all('a', class_='news_tit')
            
            if not news_items:
                return {'news_count': 0, 'sentiment_score': 0}
            
            # ê°ì„± ë¶„ì„ í‚¤ì›Œë“œ
            positive = ['ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ì‹¤ì ê°œì„ ', 'ìˆ˜ì£¼', 'ê³„ì•½', 'ì„±ì¥', 'í˜¸ì¡°']
            negative = ['í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ì ì', 'íš¡ë ¹', 'ë°°ì„', 'ê°ì‚¬ì˜ê²¬', 'í•œì •', 'ë¶€ì ì •', 'ì†ì‹¤']
            
            sentiment = 0
            for item in news_items[:10]:
                title = item.text
                for kw in positive:
                    if kw in title:
                        sentiment += 1
                for kw in negative:
                    if kw in title:
                        sentiment -= 1
            
            return {
                'news_count': len(news_items[:10]),
                'sentiment_score': sentiment
            }
            
        except Exception as e:
            return {'news_count': 0, 'sentiment_score': 0}
    
    # =========================================
    # 4. ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ ë³‘í•©
    # =========================================
    
    def update_stock_file(self, stock_code, stock_name):
        """ê¸°ì¡´ ê°œë³„ íŒŒì¼ì— ì¶”ê°€ ë°ì´í„° ë³‘í•©"""
        
        # ì´ë¯¸ ì™„ë£Œí–ˆìœ¼ë©´ ìŠ¤í‚µ
        if stock_code in self.progress['completed']:
            print(f"   âœ… ì´ë¯¸ ì™„ë£Œ")
            return True
        
        file_path = self.data_dir / f"{stock_code}_{stock_name}.parquet"
        
        if not file_path.exists():
            print(f"   âŒ íŒŒì¼ ì—†ìŒ")
            return False
        
        try:
            df = pd.read_parquet(file_path)
            
            if 'Date' in df.columns:
                df = df.set_index('Date')
            elif df.index.name != 'Date':
                df.index.name = 'Date'
            
            start_date = df.index.min()
            end_date = df.index.max()
            
            # 1. í”„ë¡œê·¸ë¨ ë§¤ë§¤
            print("   1ï¸âƒ£ í”„ë¡œê·¸ë¨ ë§¤ë§¤...", end=' ')
            df_program = self.collect_program_trading(stock_code, start_date, end_date)
            if df_program is not None and len(df_program) > 0:
                # ê¸°ì¡´ ì»¬ëŸ¼ ë®ì–´ì“°ê¸°
                for date, value in df_program['program_net'].items():
                    if date in df.index:
                        df.loc[date, 'program_net'] = value
                print(f"âœ… {len(df_program)}ì¼")
            else:
                print("âš ï¸ ë°ì´í„° ì—†ìŒ")
            
            time.sleep(0.5)  # í¬ë¡¤ë§ ë¶€í•˜ ë°©ì§€
            
            # 2. ê³µì‹œ (ë”ë¯¸)
            print("   2ï¸âƒ£ ê³µì‹œ ë°ì´í„°...", end=' ')
            df_disclosure = self.collect_disclosure(stock_code, start_date, end_date)
            if df_disclosure is not None:
                for date in df_disclosure.index:
                    if date in df.index:
                        df.loc[date, 'disclosure_count'] = df_disclosure.loc[date, 'disclosure_count']
                        df.loc[date, 'disclosure_impact'] = df_disclosure.loc[date, 'disclosure_impact']
                print("âœ… (ë”ë¯¸)")
            else:
                print("âš ï¸ ì‹¤íŒ¨")
            
            # 3. ë‰´ìŠ¤ ê°ì„± (ê¸‰ë½ ë‚ ì§œë§Œ ìˆ˜ì§‘ - ì‹œê°„ ì ˆì•½)
            print("   3ï¸âƒ£ ë‰´ìŠ¤ ê°ì„±...", end=' ')
            
            # crash = 1ì¸ ë‚ ì§œë§Œ ìˆ˜ì§‘
            crash_dates = df[df['crash'] == 1].index
            
            if len(crash_dates) > 0:
                print(f"ê¸‰ë½ {len(crash_dates)}ì¼ ìˆ˜ì§‘ ì¤‘...", end=' ')
                
                for crash_date in crash_dates:
                    news = self.collect_news_sentiment(stock_name, crash_date)
                    df.loc[crash_date, 'news_count'] = news['news_count']
                    df.loc[crash_date, 'sentiment_score'] = news['sentiment_score']
                    time.sleep(0.3)
                
                # ê¸‰ë½ ì•„ë‹Œ ë‚ ì€ 0
                df['news_count'] = df['news_count'].fillna(0)
                df['sentiment_score'] = df['sentiment_score'].fillna(0)
                print("âœ…")
            else:
                print("ê¸‰ë½ ì—†ìŒ - ìŠ¤í‚µ")
            
            # ì €ì¥
            df.reset_index().to_parquet(file_path, index=False)
            
            # ì§„í–‰ìƒí™© ì €ì¥
            self.save_progress(stock_code)
            
            return True
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ì „ì²´ íŒŒì¼ ì—…ë°ì´íŠ¸"""
    collector = EnhancedDataCollector()
    
    # ê°œë³„ íŒŒì¼ ëª©ë¡
    data_dir = Path('./data/crash_rebound')
    files = list(data_dir.glob('*.parquet'))
    files = [f for f in files if f.name != 'all_stocks_3years.parquet']
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print(f"ì´ {len(files)}ê°œ íŒŒì¼")
    print(f"ì™„ë£Œ: {len(collector.progress['completed'])}ê°œ")
    print(f"ë‚¨ì€: {len(files) - len(collector.progress['completed'])}ê°œ")
    print(f"{'='*60}\n")
    
    success = 0
    fail = 0
    
    for i, file_path in enumerate(files, 1):
        parts = file_path.stem.split('_')
        if len(parts) < 2:
            continue
        
        stock_code = parts[0]
        stock_name = '_'.join(parts[1:])
        
        print(f"[{i}/{len(files)}] {stock_name} ({stock_code})")
        
        if collector.update_stock_file(stock_code, stock_name):
            success += 1
        else:
            fail += 1
        
        # ì§„í–‰ë¥  ì¶œë ¥
        if i % 100 == 0:
            print(f"\n{'='*60}")
            print(f"ì§„í–‰: {i}/{len(files)} ({i/len(files)*100:.1f}%)")
            print(f"ì„±ê³µ: {success}, ì‹¤íŒ¨: {fail}")
            print(f"{'='*60}\n")
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ì„±ê³µ: {success}, ì‹¤íŒ¨: {fail}")
    print(f"{'='*60}")


if __name__ == '__main__':
    main()
