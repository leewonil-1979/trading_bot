"""
ê¸‰ë½ í›„ ë°˜ë“± ì˜ˆì¸¡ AI ëª¨ë¸ í•™ìŠµ

ëª¨ë¸: LightGBM (Gradient Boosting)
ëª©í‘œ: ê¸‰ë½ í›„ 5ì¼ ë‚´ +10% ì´ìƒ ë°˜ë“± ì˜ˆì¸¡
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import joblib


class CrashReboundModel:
    """ê¸‰ë½ í›„ ë°˜ë“± ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, data_path='./data/crash_rebound/all_stocks_3years.parquet'):
        self.data_path = Path(data_path)
        self.model = None
        self.feature_importance = None
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤– ê¸‰ë½ í›„ ë°˜ë“± ì˜ˆì¸¡ AI ëª¨ë¸ í•™ìŠµ")
        print(f"{'='*60}\n")
    
    # =========================================
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    # =========================================
    
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        df = pd.read_parquet(self.data_path)
        
        print(f"âœ… ì´ ë°ì´í„°: {len(df):,}í–‰")
        print(f"   ê¸‰ë½ ì´ë²¤íŠ¸: {df['crash'].sum():,}íšŒ")
        print(f"   ì„±ê³µ ë°˜ë“±: {df['success'].sum():,}íšŒ")
        print(f"   ì„±ê³µë¥ : {df['success'].sum() / df['crash'].sum() * 100:.1f}%\n")
        
        return df
    
    def prepare_features(self, df):
        """
        í•™ìŠµìš© Feature ì¤€ë¹„
        
        Returns:
            X: Feature DataFrame
            y: Label (success)
        """
        print("ğŸ”§ Feature ì¤€ë¹„ ì¤‘...")
        
        # ê¸‰ë½ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
        df_crash = df[df['crash'] == 1].copy()
        
        print(f"   ê¸‰ë½ ì´ë²¤íŠ¸: {len(df_crash):,}ê°œ")
        
        # Feature ì„ íƒ
        feature_cols = [
            # ê¸‰ë½ ì •ë³´
            'crash_rate',
            
            # ì£¼ê°€ ì •ë³´
            'close', 'volume', 'change_pct',
            
            # ì´ë™í‰ê· 
            'ma5', 'ma20', 'ma60',
            
            # ê±°ë˜ëŸ‰
            'volume_ma20', 'volume_spike',
            
            # ê¸°ìˆ ì  ì§€í‘œ
            'rsi', 'macd', 'macd_signal', 'macd_diff',
            'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',
            'stoch_k', 'stoch_d', 'atr',
            
            # íˆ¬ììë³„ ë§¤ë§¤ (ì¼ë¶€ ì¢…ëª©ì€ 0)
            'institution_net', 'foreign_net', 'individual_net', 'program_net'
        ]
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        df_crash = df_crash.dropna(subset=feature_cols + ['success'])
        
        X = df_crash[feature_cols]
        y = df_crash['success']
        
        print(f"   ìµœì¢… ë°ì´í„°: {len(X):,}ê°œ")
        print(f"   ì„±ê³µ ë°˜ë“±: {y.sum():,}ê°œ ({y.sum() / len(y) * 100:.1f}%)")
        print(f"   Feature ìˆ˜: {len(feature_cols)}ê°œ\n")
        
        return X, y, df_crash
    
    # =========================================
    # 2. ëª¨ë¸ í•™ìŠµ
    # =========================================
    
    def train(self, X, y):
        """
        LightGBM ëª¨ë¸ í•™ìŠµ
        """
        print("ğŸ“ ëª¨ë¸ í•™ìŠµ ì¤‘...\n")
        
        # Train/Test ë¶„í•  (ì‹œê³„ì—´ ê³ ë ¤ - ìµœê·¼ 20%ë¥¼ í…ŒìŠ¤íŠ¸)
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
        
        print(f"   í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê°œ")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê°œ\n")
        
        # LightGBM ë°ì´í„°ì…‹
        train_data = lgb.Dataset(X_train, label=y_train)
        test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'binary',
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': 42
        }
        
        # í•™ìŠµ
        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=500,
            valid_sets=[train_data, test_data],
            valid_names=['train', 'test'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=50),
                lgb.log_evaluation(period=100)
            ]
        )
        
        print("\nâœ… í•™ìŠµ ì™„ë£Œ!\n")
        
        return X_train, X_test, y_train, y_test
    
    # =========================================
    # 3. ëª¨ë¸ í‰ê°€
    # =========================================
    
    def evaluate(self, X_test, y_test):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...\n")
        
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ì˜ˆì¸¡
        y_pred_proba = self.model.predict(X_test)  # type: ignore
        y_pred = (y_pred_proba > 0.5).astype(int)  # type: ignore
        
        # í‰ê°€ ì§€í‘œ
        print("=" * 60)
        print("ë¶„ë¥˜ ì„±ëŠ¥")
        print("=" * 60)
        print(classification_report(y_test, y_pred, target_names=['ì‹¤íŒ¨', 'ì„±ê³µ']))
        
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        print("\nConfusion Matrix:")
        print(f"              ì˜ˆì¸¡ ì‹¤íŒ¨  ì˜ˆì¸¡ ì„±ê³µ")
        print(f"ì‹¤ì œ ì‹¤íŒ¨:     {cm[0][0]:>6}    {cm[0][1]:>6}")
        print(f"ì‹¤ì œ ì„±ê³µ:     {cm[1][0]:>6}    {cm[1][1]:>6}\n")
        
        # AUC
        auc = roc_auc_score(y_test, y_pred_proba)  # type: ignore
        print(f"AUC Score: {auc:.4f}\n")
        
        return y_pred_proba
    
    def analyze_feature_importance(self):
        """Feature ì¤‘ìš”ë„ ë¶„ì„"""
        print("ğŸ“ˆ Feature ì¤‘ìš”ë„ ë¶„ì„...\n")
        
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        importance = self.model.feature_importance(importance_type='gain')  # type: ignore
        feature_names = self.model.feature_name()  # type: ignore
        
        self.feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        print("Top 10 ì¤‘ìš” Feature:")
        print(self.feature_importance.head(10).to_string(index=False))
        print()
    
    # =========================================
    # 4. ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜
    # =========================================
    
    def simulate_profit(self, df_crash, y_pred_proba, threshold=0.6):
        """
        ì‹¤ì „ ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜
        
        Args:
            threshold: ë§¤ìˆ˜ í™•ë¥  ì„ê³„ê°’ (0.6 = 60% ì´ìƒë§Œ ë§¤ìˆ˜)
        """
        print(f"ğŸ’° ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜ (í™•ë¥  {threshold*100:.0f}% ì´ìƒë§Œ ë§¤ìˆ˜)\n")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ (ìµœê·¼ 20%)
        split_idx = int(len(df_crash) * 0.8)
        df_test = df_crash.iloc[split_idx:].copy()
        df_test['pred_proba'] = y_pred_proba
        
        # ë§¤ìˆ˜ ëŒ€ìƒ (í™•ë¥  threshold ì´ìƒ)
        df_trade = df_test[df_test['pred_proba'] >= threshold].copy()
        
        print(f"   í…ŒìŠ¤íŠ¸ ê¸‰ë½: {len(df_test)}íšŒ")
        print(f"   ë§¤ìˆ˜ ëŒ€ìƒ: {len(df_trade)}íšŒ ({len(df_trade)/len(df_test)*100:.1f}%)\n")
        
        if len(df_trade) == 0:
            print("âš ï¸ ë§¤ìˆ˜ ëŒ€ìƒ ì—†ìŒ (ì„ê³„ê°’ ë„ˆë¬´ ë†’ìŒ)")
            return
        
        # ìˆ˜ìµ ê³„ì‚°
        total_profit = 0
        win_count = 0
        lose_count = 0
        
        for idx, row in df_trade.iterrows():
            # 5ì¼ ë‚´ ìµœëŒ€ ë°˜ë“±ë¥ 
            profit = row['rebound_d5']
            
            if profit >= 0.10:  # +10% ì´ìƒ
                win_count += 1
                total_profit += 0.10  # ëª©í‘œê°€ ë„ë‹¬, +10% ìˆ˜ìµ
            elif profit >= 0.05:  # +5~10%
                win_count += 1
                total_profit += profit  # ì¼ë¶€ ìˆ˜ìµ
            else:  # ì†ì ˆ
                lose_count += 1
                total_profit -= 0.02  # -2% ì†ì ˆ
        
        # í†µê³„
        total_trades = len(df_trade)
        win_rate = win_count / total_trades * 100
        avg_profit = total_profit / total_trades * 100
        
        print("=" * 60)
        print("ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        print(f"ì´ ê±°ë˜: {total_trades}íšŒ")
        print(f"ì„±ê³µ: {win_count}íšŒ")
        print(f"ì‹¤íŒ¨: {lose_count}íšŒ")
        print(f"ìŠ¹ë¥ : {win_rate:.1f}%")
        print(f"í‰ê·  ìˆ˜ìµ: {avg_profit:+.2f}%")
        print(f"ì´ ìˆ˜ìµë¥ : {total_profit*100:+.1f}%")
        
        # ì‹¤ì „ ìˆ˜ìµ ì¶”ì •
        initial_capital = 10000000  # 1ì²œë§Œì›
        position_size = 1000000     # 1íšŒ 100ë§Œì›
        
        estimated_profit = total_profit * position_size * total_trades
        final_capital = initial_capital + estimated_profit
        
        print(f"\nì‹¤ì „ ì¶”ì • (ì´ˆê¸° ìë³¸ 1,000ë§Œì›, 1íšŒ 100ë§Œì›):")
        print(f"   ì˜ˆìƒ ìˆ˜ìµ: {estimated_profit:+,.0f}ì›")
        print(f"   ìµœì¢… ìë³¸: {final_capital:,.0f}ì›")
        print(f"   ìˆ˜ìµë¥ : {estimated_profit/initial_capital*100:+.1f}%")
        print("=" * 60 + "\n")
    
    # =========================================
    # 5. ëª¨ë¸ ì €ì¥
    # =========================================
    
    def save_model(self, output_dir='./models'):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            print("âŒ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥
        model_path = output_dir / 'crash_rebound_model.txt'
        self.model.save_model(str(model_path))
        print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
        
        # Feature ì¤‘ìš”ë„ ì €ì¥
        if self.feature_importance is not None:
            importance_path = output_dir / 'feature_importance.csv'
            self.feature_importance.to_csv(importance_path, index=False)
            print(f"âœ… Feature ì¤‘ìš”ë„ ì €ì¥: {importance_path}\n")
    
    # =========================================
    # 6. ì‹¤í–‰
    # =========================================
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_data()
        
        # 2. Feature ì¤€ë¹„
        X, y, df_crash = self.prepare_features(df)
        
        # 3. ëª¨ë¸ í•™ìŠµ
        X_train, X_test, y_train, y_test = self.train(X, y)
        
        # 4. ëª¨ë¸ í‰ê°€
        y_pred_proba = self.evaluate(X_test, y_test)
        
        # 5. Feature ì¤‘ìš”ë„
        self.analyze_feature_importance()
        
        # 6. ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜
        self.simulate_profit(df_crash, y_pred_proba, threshold=0.6)
        
        # 7. ëª¨ë¸ ì €ì¥
        self.save_model()
        
        print("\n" + "="*60)
        print("ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print("="*60)


def main():
    """ì‹¤í–‰"""
    model = CrashReboundModel()
    model.run()


if __name__ == '__main__':
    main()
